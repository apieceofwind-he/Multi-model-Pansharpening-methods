"""
åŸºäºæ®‹å·®å­¦ä¹ çš„è½»é‡çº§å·ç§¯ç¥ç»ç½‘ç»œæ¨¡å‹è®­ç»ƒ - è‡ªç›‘ç£ç‰ˆæœ¬
ä¿®å¤ç‰ˆï¼šè§£å†³æŸå¤±å€¼å¼‚å¸¸é—®é¢˜
"""

import os
import glob
import time
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
import torch.nn.functional as F
import tifffile as tiff
import numpy as np
from tqdm import tqdm
import warnings
import argparse
import csv
import matplotlib.pyplot as plt
from datetime import datetime
import rasterio
from pathlib import Path

warnings.filterwarnings('ignore')


# ===================== 1. å‘½ä»¤è¡Œå‚æ•°è§£æ =====================
def parse_args():
    parser = argparse.ArgumentParser(description='è‡ªç›‘ç£è½»é‡Pansharpeningèåˆæ¨¡å‹')

    # åŸºç¡€è·¯å¾„å‚æ•°
    parser.add_argument('--data_root', default='./data', type=str,
                        help='æ•°æ®æ ¹ç›®å½•')

    # è®­ç»ƒå‚æ•°
    parser.add_argument('--batch_size', default=4, type=int, help='æ‰¹æ¬¡å¤§å°')
    parser.add_argument('--epochs', default=50, type=int, help='è®­ç»ƒè½®æ•°')
    parser.add_argument('--lr', default=1e-4, type=float, help='å­¦ä¹ ç‡')
    parser.add_argument('--feat_ch', default=32, type=int, help='ç‰¹å¾é€šé“æ•°')

    # æŸå¤±æƒé‡ï¼ˆè°ƒæ•´ä¸ºæ›´åˆç†çš„å€¼ï¼‰
    parser.add_argument('--recon_weight', default=1.0, type=float, help='é‡å»ºæŸå¤±æƒé‡')
    parser.add_argument('--spatial_weight', default=0.2, type=float, help='ç©ºé—´æŸå¤±æƒé‡')  # é™ä½
    parser.add_argument('--spectral_weight', default=0.1, type=float, help='å…‰è°±æŸå¤±æƒé‡')  # å¤§å¹…é™ä½

    # # æŸå¤±æƒé‡ï¼ˆè°ƒæ•´ä¸ºæ›´åˆç†çš„å€¼ï¼‰
    # parser.add_argument('--recon_weight', default=1.0, type=float, help='é‡å»ºæŸå¤±æƒé‡')
    # parser.add_argument('--spatial_weight', default=0.05, type=float, help='ç©ºé—´æŸå¤±æƒé‡')  # é™ä½
    # parser.add_argument('--spectral_weight', default=0.1, type=float, help='å…‰è°±æŸå¤±æƒé‡')  # å¤§å¹…é™ä½

    # è®¾å¤‡å‚æ•°
    parser.add_argument('--device', default='cuda' if torch.cuda.is_available() else 'cpu',
                        type=str, help='è®­ç»ƒè®¾å¤‡')

    args = parser.parse_args()
    return args


# ===================== 2. ä¿®å¤çš„æŸå¤±å‡½æ•° =====================
class StablePanGuidedSpatialLoss(nn.Module):
    """ç¨³å®šçš„ç©ºé—´æŸå¤±å‡½æ•°"""

    def __init__(self):
        super().__init__()

        # å®šä¹‰ç¨³å®šçš„å·ç§¯æ ¸
        sobel_x = torch.tensor([[-1.0, 0.0, 1.0], [-2.0, 0.0, 2.0], [-1.0, 0.0, 1.0]]).view(1, 1, 3, 3)
        sobel_y = torch.tensor([[-1.0, -2.0, -1.0], [0.0, 0.0, 0.0], [1.0, 2.0, 1.0]]).view(1, 1, 3, 3)
        lap = torch.tensor([[0.0, 1.0, 0.0], [1.0, -4.0, 1.0], [0.0, 1.0, 0.0]]).view(1, 1, 3, 3)

        self.register_buffer('sobel_x', sobel_x)
        self.register_buffer('sobel_y', sobel_y)
        self.register_buffer('lap', lap)

    def gradient_map(self, x):
        """è®¡ç®—æ¢¯åº¦å›¾ï¼ˆæ·»åŠ ç¨³å®šæ€§å¤„ç†ï¼‰"""
        # ç¡®ä¿è¾“å…¥åœ¨åˆç†èŒƒå›´å†…
        x = torch.clamp(x, 0.0, 1.0)

        gx = F.conv2d(x, self.sobel_x, padding=1)
        gy = F.conv2d(x, self.sobel_y, padding=1)
        return torch.abs(gx) + torch.abs(gy)

    def laplacian_map(self, x):
        """è®¡ç®—æ‹‰æ™®æ‹‰æ–¯å›¾"""
        x = torch.clamp(x, 0.0, 1.0)
        return F.conv2d(x, self.lap, padding=1)

    def forward(self, fused_ms, pan):
        """è®¡ç®—ç©ºé—´æŸå¤±ï¼ˆæ·»åŠ æ•°å€¼ç¨³å®šæ€§ï¼‰"""
        # å¼ºåº¦åˆ†é‡è®¡ç®—
        fused_i = torch.clamp(fused_ms.mean(dim=1, keepdim=True), 0.0, 1.0)
        pan = torch.clamp(pan, 0.0, 1.0)

        # æ¢¯åº¦ä¸€è‡´æ€§ï¼ˆæ·»åŠ ç¨³å®šæ€§å¤„ç†ï¼‰
        fused_grad = self.gradient_map(fused_i)
        pan_grad = self.gradient_map(pan)
        grad_loss = F.l1_loss(fused_grad, pan_grad)

        # æ‹‰æ™®æ‹‰æ–¯ä¸€è‡´æ€§
        fused_lap = self.laplacian_map(fused_i)
        pan_lap = self.laplacian_map(pan)
        lap_loss = F.l1_loss(torch.abs(fused_lap), torch.abs(pan_lap))

        return grad_loss, lap_loss


class StableSelfSupervisedLoss(nn.Module):
    """ç¨³å®šçš„è‡ªç›‘ç£æŸå¤±å‡½æ•°"""

    def __init__(self, recon_weight=1.0, spatial_weight=0.05, spectral_weight=0.1):
        super().__init__()
        self.recon_weight = recon_weight
        self.spatial_weight = spatial_weight
        self.spectral_weight = spectral_weight

        self.spatial_loss_fn = StablePanGuidedSpatialLoss()

    def degrade_image(self, hr_image, scale_factor=4):
        """ç¨³å®šçš„å›¾åƒé€€åŒ–æ¨¡æ‹Ÿ"""
        if scale_factor <= 1:
            return hr_image

        batch_size, channels, height, width = hr_image.shape
        new_height = max(height // scale_factor, 1)
        new_width = max(width // scale_factor, 1)

        # åŒä¸‰æ¬¡æ’å€¼ä¸‹é‡‡æ ·+ä¸Šé‡‡æ ·
        degraded = F.interpolate(hr_image, size=(new_height, new_width),
                                 mode='bicubic', align_corners=False)
        degraded_hr = F.interpolate(degraded, size=(height, width),
                                    mode='bicubic', align_corners=False)

        return torch.clamp(degraded_hr, 0.0, 1.0)

    def stable_spectral_loss(self, fused, ms_lr):
        """ç¨³å®šçš„å…‰è°±æŸå¤±è®¡ç®—"""
        # ä¸Šé‡‡æ ·MSåˆ°èåˆç»“æœå°ºå¯¸
        ms_up = F.interpolate(ms_lr, size=fused.shape[2:],
                              mode='bicubic', align_corners=False)

        # ç®€å•çš„L1æŸå¤±ï¼ˆæ›´ç¨³å®šï¼‰
        spectral_loss = F.l1_loss(fused, ms_up)

        return spectral_loss

    def forward(self, fused, pan, ms_lr):
        """ç¨³å®šçš„æŸå¤±è®¡ç®—"""
        losses = {}

        # ç¡®ä¿è¾“å…¥åœ¨åˆç†èŒƒå›´å†…
        fused = torch.clamp(fused, 0.0, 1.0)
        pan = torch.clamp(pan, 0.0, 1.0)
        ms_lr = torch.clamp(ms_lr, 0.0, 1.0)

        # 1. é‡å»ºæŸå¤±
        fused_degraded = self.degrade_image(fused)
        recon_loss = F.l1_loss(fused_degraded, ms_lr)
        losses['recon'] = recon_loss

        # 2. ç©ºé—´æŸå¤±
        grad_loss, lap_loss = self.spatial_loss_fn(fused, pan)
        spatial_loss = grad_loss + 0.2 * lap_loss
        losses['spatial'] = spatial_loss

        # 3. å…‰è°±æŸå¤±ï¼ˆä½¿ç”¨ç¨³å®šç‰ˆæœ¬ï¼‰
        spectral_loss = self.stable_spectral_loss(fused, ms_lr)
        losses['spectral'] = spectral_loss

        # æ€»æŸå¤±ï¼ˆæ·»åŠ æ•°å€¼æ£€æŸ¥ï¼‰
        total_loss = (self.recon_weight * recon_loss +
                      self.spatial_weight * spatial_loss +
                      self.spectral_weight * spectral_loss)

        # æ£€æŸ¥æŸå¤±å€¼æ˜¯å¦åˆç†
        if torch.isnan(total_loss) or torch.isinf(total_loss):
            print(
                f"è­¦å‘Š: æŸå¤±å€¼å¼‚å¸¸ - recon: {recon_loss:.4f}, spatial: {spatial_loss:.4f}, spectral: {spectral_loss:.4f}")
            # ä½¿ç”¨é»˜è®¤æŸå¤±
            total_loss = recon_loss + 0.1 * spatial_loss + 0.01 * spectral_loss

        losses['total'] = total_loss

        return total_loss, losses


# ===================== 3. ç®€åŒ–çš„æ¨¡å‹å®šä¹‰ =====================
class ResidualBlock(nn.Module):
    """æ®‹å·®å—"""

    def __init__(self, in_ch, out_ch):
        super().__init__()
        self.conv = nn.Sequential(
            nn.Conv2d(in_ch, out_ch, 3, padding=1),
            nn.LeakyReLU(0.2, inplace=True),
            nn.Conv2d(out_ch, out_ch, 3, padding=1)
        )
        self.shortcut = nn.Conv2d(in_ch, out_ch, 1) if in_ch != out_ch else nn.Identity()
        self.act = nn.LeakyReLU(0.2, inplace=True)

    def forward(self, x):
        residual = self.shortcut(x)
        x = self.conv(x)
        return self.act(x + residual)


class SimplePansharpen(nn.Module):
    """ç®€åŒ–ä½†ç¨³å®šçš„æ¨¡å‹"""

    def __init__(self, ms_ch=8, pan_ch=1, feat_ch=32):
        super().__init__()

        # PANåˆ†æ”¯
        self.pan_conv = nn.Sequential(
            nn.Conv2d(pan_ch, feat_ch, 3, padding=1),
            nn.LeakyReLU(0.2, inplace=True),
            nn.Conv2d(feat_ch, feat_ch, 3, padding=1),
            nn.LeakyReLU(0.2, inplace=True)
        )

        # MSåˆ†æ”¯
        self.ms_conv = nn.Sequential(
            nn.Conv2d(ms_ch, feat_ch, 3, padding=1),
            nn.LeakyReLU(0.2, inplace=True),
            nn.Conv2d(feat_ch, feat_ch, 3, padding=1),
            nn.LeakyReLU(0.2, inplace=True)
        )

        # èåˆ
        self.fusion = nn.Sequential(
            nn.Conv2d(feat_ch * 2, feat_ch, 3, padding=1),
            nn.LeakyReLU(0.2, inplace=True),
            nn.Conv2d(feat_ch, ms_ch, 1)
        )

    def forward(self, ms, pan):
        # MSä¸Šé‡‡æ ·
        ms_up = F.interpolate(ms, scale_factor=1, mode='bicubic', align_corners=False)

        # ç‰¹å¾æå–
        pan_feat = self.pan_conv(pan)
        ms_feat = self.ms_conv(ms_up)

        # èåˆ
        fused_feat = torch.cat([ms_feat, pan_feat], dim=1)
        output = self.fusion(fused_feat)

        return torch.clamp(output, 0.0, 1.0)


# ===================== 4. ç¨³å®šçš„æ•°æ®é›† ======================
class StablePansharpenDataset(Dataset):
    """ç¨³å®šçš„æ•°æ®é›†åŠ è½½"""

    def __init__(self, data_root, phase='train'):
        self.phase = phase
        self.data_root = data_root

        if phase == 'train':
            data_dir = os.path.join(data_root, 'train_data', 'train')
        elif phase == 'test':
            data_dir = os.path.join(data_root, 'test_data', 'test')
        else:  # real_test
            data_dir = os.path.join(data_root, 'real_data')

        self.data_dir = data_dir
        self.file_pairs = self._collect_file_pairs()
        print(f"ã€{phase}é˜¶æ®µã€‘æ‰¾åˆ° {len(self.file_pairs)} ä¸ªæ ·æœ¬")

    def _collect_file_pairs(self):
        """æ”¶é›†æ–‡ä»¶å¯¹"""
        file_pairs = []

        if self.phase in ['train', 'test']:
            # è®­ç»ƒ/æµ‹è¯•é˜¶æ®µ
            pan_files = sorted(glob.glob(os.path.join(self.data_dir, '*_pan.tif')))
            mul_files = sorted(glob.glob(os.path.join(self.data_dir, '*_mul.tif')))

            # æŒ‰æ–‡ä»¶åé…å¯¹
            pan_dict = {}
            for f in pan_files:
                base_name = os.path.basename(f).replace('_pan.tif', '')
                pan_dict[base_name] = f

            mul_dict = {}
            for f in mul_files:
                base_name = os.path.basename(f).replace('_mul.tif', '')
                mul_dict[base_name] = f

            common_keys = set(pan_dict.keys()) & set(mul_dict.keys())
            for key in sorted(common_keys):
                file_pairs.append((pan_dict[key], mul_dict[key]))

        else:  # real_test
            # çœŸå®æµ‹è¯•é˜¶æ®µ
            ms_up_dir = os.path.join(self.data_dir, 'MS_up_800')
            pan_cut_dir = os.path.join(self.data_dir, 'PAN_cut_800')

            if os.path.exists(ms_up_dir) and os.path.exists(pan_cut_dir):
                ms_files = sorted(glob.glob(os.path.join(ms_up_dir, '*.tif')))
                pan_files = sorted(glob.glob(os.path.join(pan_cut_dir, '*.tif')))

                min_len = min(len(ms_files), len(pan_files))
                for i in range(min_len):
                    file_pairs.append((pan_files[i], ms_files[i]))

        return file_pairs

    def safe_normalize(self, data):
        """å®‰å…¨çš„å½’ä¸€åŒ–å‡½æ•°"""
        if len(data.shape) == 2:
            min_val = data.min()
            max_val = data.max()
            if max_val - min_val < 1e-6:
                return np.zeros_like(data)
            return (data - min_val) / (max_val - min_val + 1e-8)
        else:
            normalized = []
            for i in range(data.shape[0]):
                band = data[i]
                min_val = band.min()
                max_val = band.max()
                if max_val - min_val < 1e-6:
                    normalized.append(np.zeros_like(band))
                else:
                    normalized.append((band - min_val) / (max_val - min_val + 1e-8))
            return np.stack(normalized, axis=0)

    def __len__(self):
        return len(self.file_pairs)

    def __getitem__(self, idx):
        pan_path, ms_path = self.file_pairs[idx]

        try:
            # è¯»å–æ•°æ®
            with rasterio.open(pan_path) as src:
                pan = src.read().astype(np.float32)
            with rasterio.open(ms_path) as src:
                ms = src.read().astype(np.float32)

            # å®‰å…¨å½’ä¸€åŒ–
            pan = self.safe_normalize(pan)
            ms = self.safe_normalize(ms)

            # è°ƒæ•´ç»´åº¦
            if len(pan.shape) == 2:
                pan = pan[np.newaxis, :]  # (1, H, W)
            if len(ms.shape) == 2:
                ms = ms[np.newaxis, :]  # (C, H, W)

            # è½¬æ¢ä¸ºå¼ é‡
            pan_tensor = torch.FloatTensor(pan)
            ms_tensor = torch.FloatTensor(ms)

            return {
                'pan': pan_tensor,
                'ms': ms_tensor,
                'pan_path': pan_path,
                'ms_path': ms_path
            }

        except Exception as e:
            print(f"è¯»å–æ ·æœ¬ {idx} å¤±è´¥: {e}")
            # è¿”å›å®‰å…¨çš„é»˜è®¤æ•°æ®
            return {
                'pan': torch.zeros((1, 256, 256)),
                'ms': torch.zeros((8, 64, 64)),
                'pan_path': 'error',
                'ms_path': 'error'
            }


# ===================== 5. ç¨³å®šçš„è®­ç»ƒå‡½æ•° =====================
def stable_train(model, train_loader, val_loader, args):
    """ç¨³å®šçš„è®­ç»ƒå‡½æ•°"""

    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir = Path(args.output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)

    # ä½¿ç”¨ç¨³å®šçš„æŸå¤±å‡½æ•°
    criterion = StableSelfSupervisedLoss(
        recon_weight=args.recon_weight,
        spatial_weight=args.spatial_weight,
        spectral_weight=args.spectral_weight
    )

    # ä¼˜åŒ–å™¨ï¼ˆæ·»åŠ æ¢¯åº¦è£å‰ªï¼‰
    optimizer = optim.Adam(model.parameters(), lr=args.lr, weight_decay=1e-5)
    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.5)

    # è®­ç»ƒå†å²
    history = {
        'epoch': [], 'train_loss': [], 'val_loss': [],
        'train_recon': [], 'val_recon': [],
        'train_spatial': [], 'val_spatial': [],
        'train_spectral': [], 'val_spectral': []
    }

    best_val_loss = float('inf')
    best_model_path = output_dir / 'best_model.pth'

    print("å¼€å§‹ç¨³å®šè®­ç»ƒ...")

    for epoch in range(args.epochs):
        # è®­ç»ƒé˜¶æ®µ
        model.train()
        train_metrics = {'total': 0.0, 'recon': 0.0, 'spatial': 0.0, 'spectral': 0.0}
        train_samples = 0

        pbar = tqdm(train_loader, desc=f'Epoch {epoch + 1}/{args.epochs}')
        for batch in pbar:
            pan = batch['pan'].to(args.device)
            ms = batch['ms'].to(args.device)

            # æ¢¯åº¦æ¸…é›¶
            optimizer.zero_grad()

            # å‰å‘ä¼ æ’­
            fused = model(ms, pan)

            # è®¡ç®—æŸå¤±
            total_loss, losses = criterion(fused, pan, ms)

            # æ£€æŸ¥æŸå¤±æ˜¯å¦åˆç†
            if torch.isnan(total_loss) or torch.isinf(total_loss):
                print(f"è·³è¿‡æ‰¹æ¬¡: æŸå¤±å€¼å¼‚å¸¸")
                continue

            # åå‘ä¼ æ’­ï¼ˆæ·»åŠ æ¢¯åº¦è£å‰ªï¼‰
            total_loss.backward()
            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
            optimizer.step()

            # è®°å½•æŒ‡æ ‡
            batch_size = pan.size(0)
            train_metrics['total'] += total_loss.item() * batch_size
            train_metrics['recon'] += losses['recon'].item() * batch_size
            train_metrics['spatial'] += losses['spatial'].item() * batch_size
            train_metrics['spectral'] += losses['spectral'].item() * batch_size
            train_samples += batch_size

            pbar.set_postfix({
                'Loss': f'{total_loss.item():.4f}',
                'Recon': f'{losses["recon"].item():.4f}',
                'Spatial': f'{losses["spatial"].item():.4f}'
            })

        # éªŒè¯é˜¶æ®µ
        model.eval()
        val_metrics = {'total': 0.0, 'recon': 0.0, 'spatial': 0.0, 'spectral': 0.0}
        val_samples = 0

        with torch.no_grad():
            for batch in val_loader:
                pan = batch['pan'].to(args.device)
                ms = batch['ms'].to(args.device)

                fused = model(ms, pan)
                total_loss, losses = criterion(fused, pan, ms)

                batch_size = pan.size(0)
                val_metrics['total'] += total_loss.item() * batch_size
                val_metrics['recon'] += losses['recon'].item() * batch_size
                val_metrics['spatial'] += losses['spatial'].item() * batch_size
                val_metrics['spectral'] += losses['spectral'].item() * batch_size
                val_samples += batch_size

        # è®¡ç®—å¹³å‡æŸå¤±
        train_loss = train_metrics['total'] / max(train_samples, 1)
        val_loss = val_metrics['total'] / max(val_samples, 1)

        # è®°å½•å†å²
        history['epoch'].append(epoch + 1)
        history['train_loss'].append(train_loss)
        history['val_loss'].append(val_loss)
        history['train_recon'].append(train_metrics['recon'] / max(train_samples, 1))
        history['val_recon'].append(val_metrics['recon'] / max(val_samples, 1))
        history['train_spatial'].append(train_metrics['spatial'] / max(train_samples, 1))
        history['val_spatial'].append(val_metrics['spatial'] / max(val_samples, 1))
        history['train_spectral'].append(train_metrics['spectral'] / max(train_samples, 1))
        history['val_spectral'].append(val_metrics['spectral'] / max(val_samples, 1))

        print(f'Epoch {epoch + 1}/{args.epochs}: '
              f'Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}')

        # å­¦ä¹ ç‡è°ƒæ•´
        scheduler.step()

        # ä¿å­˜æœ€ä½³æ¨¡å‹
        if val_loss < best_val_loss and not (
                torch.isnan(torch.tensor(val_loss)) or torch.isinf(torch.tensor(val_loss))):
            best_val_loss = val_loss
            torch.save(model.state_dict(), best_model_path)
            print(f"âœ… ä¿å­˜æœ€ä½³æ¨¡å‹: {best_model_path}")

    # ä¿å­˜è®­ç»ƒå†å²
    save_training_history(history, output_dir / 'training_history.csv')
    plot_training_curves(history, output_dir / 'training_curves.png')

    return model, history


def save_training_history(history, save_path):
    """ä¿å­˜è®­ç»ƒå†å²"""
    with open(save_path, 'w', newline='', encoding='utf-8') as f:
        writer = csv.writer(f)
        writer.writerow(['epoch', 'train_loss', 'val_loss',
                         'train_recon', 'val_recon',
                         'train_spatial', 'val_spatial',
                         'train_spectral', 'val_spectral'])

        for i in range(len(history['epoch'])):
            writer.writerow([
                history['epoch'][i],
                history['train_loss'][i],
                history['val_loss'][i],
                history['train_recon'][i],
                history['val_recon'][i],
                history['train_spatial'][i],
                history['val_spatial'][i],
                history['train_spectral'][i],
                history['val_spectral'][i]
            ])


def plot_training_curves(history, save_path):
    """ç»˜åˆ¶è®­ç»ƒæ›²çº¿"""
    fig, axes = plt.subplots(2, 2, figsize=(12, 8))

    # æ€»æŸå¤±
    axes[0, 0].plot(history['epoch'], history['train_loss'], label='Train')
    axes[0, 0].plot(history['epoch'], history['val_loss'], label='Validation')
    axes[0, 0].set_title('Total Loss')
    axes[0, 0].set_xlabel('Epoch')
    axes[0, 0].set_ylabel('Loss')
    axes[0, 0].legend()
    axes[0, 0].grid(True, alpha=0.3)

    # é‡å»ºæŸå¤±
    axes[0, 1].plot(history['epoch'], history['train_recon'], label='Train')
    axes[0, 1].plot(history['epoch'], history['val_recon'], label='Validation')
    axes[0, 1].set_title('Reconstruction Loss')
    axes[0, 1].set_xlabel('Epoch')
    axes[0, 1].set_ylabel('Loss')
    axes[0, 1].legend()
    axes[0, 1].grid(True, alpha=0.3)

    # ç©ºé—´æŸå¤±
    axes[1, 0].plot(history['epoch'], history['train_spatial'], label='Train')
    axes[1, 0].plot(history['epoch'], history['val_spatial'], label='Validation')
    axes[1, 0].set_title('Spatial Loss')
    axes[1, 0].set_xlabel('Epoch')
    axes[1, 0].set_ylabel('Loss')
    axes[1, 0].legend()
    axes[1, 0].grid(True, alpha=0.3)

    # å…‰è°±æŸå¤±
    axes[1, 1].plot(history['epoch'], history['train_spectral'], label='Train')
    axes[1, 1].plot(history['epoch'], history['val_spectral'], label='Validation')
    axes[1, 1].set_title('Spectral Loss')
    axes[1, 1].set_xlabel('Epoch')
    axes[1, 1].set_ylabel('Loss')
    axes[1, 1].legend()
    axes[1, 1].grid(True, alpha=0.3)

    plt.tight_layout()
    plt.savefig(save_path, dpi=150, bbox_inches='tight')
    plt.close()
    print(f"è®­ç»ƒæ›²çº¿å·²ä¿å­˜: {save_path}")


# ===================== 6. æµ‹è¯•å‡½æ•° =====================
def stable_test(model, test_loader, args, save_dir):
    model.eval()
    os.makedirs(save_dir, exist_ok=True)

    with torch.no_grad():
        for i, batch in enumerate(tqdm(test_loader, desc='æµ‹è¯•èåˆ')):
            try:
                pan = batch['pan'].to(args.device)
                ms = batch['ms'].to(args.device)

                # ç”Ÿæˆèåˆç»“æœ
                fused = model(ms, pan)

                # é‡è¦ï¼šæ£€æŸ¥æ¨¡å‹è¾“å‡ºå½¢çŠ¶
                print(f"æ¨¡å‹è¾“å‡ºå½¢çŠ¶: {fused.shape}")  # åº”è¯¥æ˜¯[1, 8, H, W]

                # è½¬æ¢ä¸ºnumpy - æ­£ç¡®å¤„ç†ç»´åº¦
                fused_np = fused.squeeze(0).cpu().numpy()  # ç§»é™¤batchç»´åº¦ -> [8, H, W]
                print(f"ä¿å­˜å‰å½¢çŠ¶: {fused_np.shape}")  # åº”è¯¥æ˜¯(8, 800, 800)

                # ç¡®ä¿æ˜¯8ä¸ªæ³¢æ®µ
                if fused_np.shape[0] != 8:
                    print(f"âš ï¸ è­¦å‘Š: èåˆç»“æœåªæœ‰{fused_np.shape[0]}ä¸ªæ³¢æ®µï¼Œåº”è¯¥æ˜¯8ä¸ª!")
                    # å¯èƒ½éœ€è¦æ£€æŸ¥æ¨¡å‹è¾“å‡º

                # æ•°å€¼èŒƒå›´æ£€æŸ¥
                fused_np = np.clip(fused_np, 0.0, 1.0)

                # è½¬æ¢ä¸º16ä½æ•´æ•°
                fused_uint16 = (fused_np * 65535).astype(np.uint16)

                # ä¿å­˜8é€šé“TIFF
                output_path = os.path.join(save_dir, f'fusion_8ch_{i:04d}.tif')
                tiff.imwrite(output_path, fused_uint16,
                             photometric='minisblack',
                             planarconfig='separate')  # ç¡®ä¿å¤šæ³¢æ®µæ­£ç¡®ä¿å­˜

            except Exception as e:
                print(f"å¤„ç†ç¬¬{i}ä¸ªæ ·æœ¬æ—¶å‡ºé”™: {e}")
                continue
    print(f"\nâœ… èåˆå®Œæˆ! å…±å¤„ç† {len(test_loader.dataset)} ä¸ªæ ·æœ¬")
    print(f"ğŸ“ ç»“æœä¿å­˜åœ¨: {save_dir}")


def visual_quality_check(ms, pan, fused, save_path):
    """è§†è§‰è´¨é‡æ£€æŸ¥"""
    import matplotlib.pyplot as plt

    # é€‰æ‹©ç”¨äºæ˜¾ç¤ºçš„æ³¢æ®µï¼ˆå‡å½©è‰²ï¼š7,3,2 -> NIR, R, Gï¼‰
    rgb_bands = [6, 2, 1]  # 0-indexed

    # åˆ›å»ºRGBå›¾åƒ
    def create_rgb(image, bands):
        if image.shape[0] >= max(bands) + 1:
            rgb = image[bands].transpose(1, 2, 0)
            # å¯¹æ¯”åº¦æ‹‰ä¼¸
            for i in range(3):
                p2, p98 = np.percentile(rgb[:, :, i], (2, 98))
                if p98 > p2:
                    rgb[:, :, i] = np.clip((rgb[:, :, i] - p2) / (p98 - p2), 0, 1)
            return rgb
        return None

    # ç”Ÿæˆå„å›¾åƒçš„RGBè§†å›¾
    ms_rgb = create_rgb(ms, rgb_bands) if ms.shape[0] >= 7 else None
    fused_rgb = create_rgb(fused, rgb_bands) if fused.shape[0] >= 7 else None

    fig, axes = plt.subplots(2, 3, figsize=(15, 10))

    # æ˜¾ç¤ºMS RGB
    if ms_rgb is not None:
        axes[0, 0].imshow(ms_rgb)
        axes[0, 0].set_title('å‚è€ƒMS (RGB)')
        axes[0, 0].axis('off')

    # æ˜¾ç¤ºPAN
    axes[0, 1].imshow(pan[0], cmap='gray')
    axes[0, 1].set_title('PANå›¾åƒ')
    axes[0, 1].axis('off')

    # æ˜¾ç¤ºèåˆç»“æœRGB
    if fused_rgb is not None:
        axes[0, 2].imshow(fused_rgb)
        axes[0, 2].set_title('èåˆç»“æœ (RGB)')
        axes[0, 2].axis('off')

    # æ˜¾ç¤ºå·®å¼‚
    if ms_rgb is not None and fused_rgb is not None:
        diff = np.abs(ms_rgb - fused_rgb).mean(axis=2)
        im = axes[1, 0].imshow(diff, cmap='hot')
        axes[1, 0].set_title('å·®å¼‚å›¾ (MS vs Fused)')
        axes[1, 0].axis('off')
        plt.colorbar(im, ax=axes[1, 0])

    # æ˜¾ç¤ºè¾¹ç¼˜å¯¹æ¯”
    from scipy import ndimage
    if fused_rgb is not None:
        edges = ndimage.sobel(fused_rgb.mean(axis=2))
        axes[1, 1].imshow(edges, cmap='gray')
        axes[1, 1].set_title('èåˆç»“æœè¾¹ç¼˜')
        axes[1, 1].axis('off')

    # æ˜¾ç¤ºPANè¾¹ç¼˜
    pan_edges = ndimage.sobel(pan[0])
    axes[1, 2].imshow(pan_edges, cmap='gray')
    axes[1, 2].set_title('PANè¾¹ç¼˜')
    axes[1, 2].axis('off')

    plt.tight_layout()
    plt.savefig(save_path, dpi=150, bbox_inches='tight')
    plt.close()
# ===================== 7. ä¸»å‡½æ•° =====================
def main():
    args = parse_args()

    # è®¾ç½®è¾“å‡ºç›®å½•
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    args.output_dir = f'./results/stable_pansharpen_{timestamp}'

    print("=" * 60)
    print("ç¨³å®šç‰ˆè‡ªç›‘ç£Pansharpeningè®­ç»ƒ")
    print(f"è®¾å¤‡: {args.device}")
    print(f"è¾“å‡ºç›®å½•: {args.output_dir}")
    print("=" * 60)

    # æ˜¾ç¤ºé…ç½®
    print("\nè®­ç»ƒé…ç½®:")
    for key, value in vars(args).items():
        print(f"  {key}: {value}")

    # åˆ›å»ºæ¨¡å‹
    model = SimplePansharpen(ms_ch=8, pan_ch=1, feat_ch=args.feat_ch).to(args.device)
    print(f"\næ¨¡å‹å‚æ•°é‡: {sum(p.numel() for p in model.parameters()):,}")

    # æ£€æŸ¥æ•°æ®ç›®å½•
    if not os.path.exists(args.data_root):
        print(f"é”™è¯¯: æ•°æ®ç›®å½•ä¸å­˜åœ¨: {args.data_root}")
        return

    # åŠ è½½æ•°æ®
    print("\nåŠ è½½æ•°æ®...")
    try:
        train_dataset = StablePansharpenDataset(args.data_root, 'train')
        val_dataset = StablePansharpenDataset(args.data_root, 'test')

        train_loader = DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True, num_workers=2)
        val_loader = DataLoader(val_dataset, batch_size=args.batch_size, shuffle=False, num_workers=2)

        print(f"è®­ç»ƒé›†: {len(train_dataset)} ä¸ªæ ·æœ¬")
        print(f"éªŒè¯é›†: {len(val_dataset)} ä¸ªæ ·æœ¬")

    except Exception as e:
        print(f"åŠ è½½æ•°æ®å¤±è´¥: {e}")
        return

    # å¼€å§‹è®­ç»ƒ
    print("\nå¼€å§‹ç¨³å®šè®­ç»ƒ...")
    model, history = stable_train(model, train_loader, val_loader, args)

    print("\nè®­ç»ƒå®Œæˆ!")

    # æµ‹è¯•çœŸå®æ•°æ®
    if os.path.exists(os.path.join(args.data_root, 'real_data')):
        print("\næµ‹è¯•çœŸå®æ•°æ®...")

        # åŠ è½½æœ€ä½³æ¨¡å‹
        best_model_path = os.path.join(args.output_dir, 'best_model.pth')
        if os.path.exists(best_model_path):
            model.load_state_dict(torch.load(best_model_path, map_location=args.device))
            print(f"åŠ è½½æœ€ä½³æ¨¡å‹: {best_model_path}")

        # æµ‹è¯•
        test_dataset = StablePansharpenDataset(args.data_root, 'real_test')
        test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)

        test_save_dir = os.path.join(args.output_dir, 'fusion_results')
        stable_test(model, test_loader, args, test_save_dir)

    print(f"\nğŸ‰ æ‰€æœ‰æµç¨‹å®Œæˆ!")
    print(f"ğŸ“ å®Œæ•´ç»“æœä¿å­˜åœ¨: {args.output_dir}")

    return model, history


if __name__ == '__main__':
    main()